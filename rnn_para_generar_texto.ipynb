{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cegacitua/colab-deep-learning/blob/main/rnn_para_generar_texto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiPOPIwuuc_o"
      },
      "source": [
        "<a class=\"anchor\" id=\"0\"></a>\n",
        "#RNN con Keras\n",
        "\n",
        "Ejemplo b&aacute;sico de una RNN con Keras para generar texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v24dXssaqp2A",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c122fda4-cf82-4189-a827-c836f709dc18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        " from google.colab import drive\n",
        " drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "IHu202ZwW0yS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02dede6d-1042-48c0-e7d6-8bec3a011efe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versión de TensorFlow: 2.15.0\n"
          ]
        }
      ],
      "source": [
        "# Importar TensorFlow y verificar su versión\n",
        "import tensorflow as tf\n",
        "print(\"Versión de TensorFlow:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ii_ccCB9uc_w",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Activation, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "def setUpTrainDataFromTxt(INPUT_FILE, SEQLEN, STEP):\n",
        "    text = \"\"\n",
        "\n",
        "    for archivo in INPUT_FILE:\n",
        "        print(\"Leyendo archivo \", archivo)\n",
        "        with open(archivo, 'rb') as fin:\n",
        "            lines = []\n",
        "            for line in fin:\n",
        "                line = line.strip().lower()\n",
        "                line = line.decode(\"ascii\", \"ignore\")\n",
        "                if len(line) == 0:\n",
        "                    continue\n",
        "                lines.append(line)\n",
        "            text = text + \" \".join(lines)\n",
        "        print(\"cantidad lineas\", len(lines))\n",
        "        print(\"largo texto\", len(text))\n",
        "\n",
        "    chars = set([c for c in text])\n",
        "    nb_chars = len(chars)\n",
        "    char2index = dict((c, i) for i, c in enumerate(chars))\n",
        "    index2char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "    input_chars = []\n",
        "    label_chars = []\n",
        "    for i in range(0, len(text) - SEQLEN, STEP):\n",
        "        input_chars.append(text[i:i + SEQLEN])\n",
        "        label_chars.append(text[i + SEQLEN])\n",
        "\n",
        "    X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
        "    y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
        "    for i, input_char in enumerate(input_chars):\n",
        "        for j, ch in enumerate(input_char):\n",
        "            X[i, j, char2index[ch]] = 1\n",
        "        y[i, char2index[label_chars[i]]] = 1\n",
        "\n",
        "    return X, y, nb_chars, input_chars, label_chars, char2index, index2char\n",
        "\n",
        "INPUT_FILE = [\n",
        "    \"/content/drive/MyDrive/Coordinacion Linea/2022S1/DLY0100/Semana 11/RNN Para generar texto/quijote.txt\",\n",
        "    \"/content/drive/MyDrive/Coordinacion Linea/2022S1/DLY0100/Semana 11/RNN Para generar texto/donjuantenorio.txt\",\n",
        "    \"/content/drive/MyDrive/Coordinacion Linea/2022S1/DLY0100/Semana 11/RNN Para generar texto/ladivinacomedia.txt\"\n",
        "]\n",
        "\n",
        "SEQLEN = 10\n",
        "STEP = 1\n",
        "\n",
        "X, y, nb_chars, input_chars, label_chars, char2index, index2char = setUpTrainDataFromTxt(INPUT_FILE, SEQLEN, STEP)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Activation, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "import requests  # Import the requests library\n",
        "\n",
        "def setUpTrainDataFromTxt(INPUT_FILE, SEQLEN, STEP):\n",
        "    text = \"\"\n",
        "\n",
        "    for url in INPUT_FILE:\n",
        "        print(\"Downloading file from \", url)\n",
        "        response = requests.get(url)  # Download the file\n",
        "        content = response.content.decode('utf-8')  # Decode the content as UTF-8\n",
        "\n",
        "        lines = []\n",
        "        for line in content.splitlines():\n",
        "            line = line.strip().lower()\n",
        "            line = line.encode('ascii', 'ignore').decode('ascii')  # Handle non-ASCII characters\n",
        "            if len(line) == 0:\n",
        "                continue\n",
        "            lines.append(line)\n",
        "        text = text + \" \".join(lines)\n",
        "        print(\"Number of lines:\", len(lines))\n",
        "        print(\"Length of text:\", len(text))\n",
        "\n",
        "    chars = set([c for c in text])\n",
        "    nb_chars = len(chars)\n",
        "    char2index = dict((c, i) for i, c in enumerate(chars))\n",
        "    index2char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "    input_chars = []\n",
        "    label_chars = []\n",
        "    for i in range(0, len(text) - SEQLEN, STEP):\n",
        "        input_chars.append(text[i:i + SEQLEN])\n",
        "        label_chars.append(text[i + SEQLEN])\n",
        "\n",
        "    # Use bool instead of np.bool\n",
        "    X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=bool)\n",
        "    y = np.zeros((len(input_chars), nb_chars), dtype=bool)\n",
        "    for i, input_char in enumerate(input_chars):\n",
        "        for j, ch in enumerate(input_char):\n",
        "            X[i, j, char2index[ch]] = 1\n",
        "        y[i, char2index[label_chars[i]]] = 1\n",
        "\n",
        "    return X, y, nb_chars, input_chars, label_chars, char2index, index2char\n",
        "\n",
        "INPUT_FILE = [\n",
        "    \"https://raw.githubusercontent.com/cegacitua/colab-deep-learning/main/quijote.txt\",\n",
        "    \"https://raw.githubusercontent.com/cegacitua/colab-deep-learning/main/donjuantenorio.txt\",\n",
        "    \"https://raw.githubusercontent.com/cegacitua/colab-deep-learning/main/ladivinacomedia.txt\"\n",
        "]\n",
        "\n",
        "SEQLEN = 10\n",
        "STEP = 1\n",
        "\n",
        "# Install requests if you don't have it\n",
        "!pip install requests\n",
        "\n",
        "X, y, nb_chars, input_chars, label_chars, char2index, index2char = setUpTrainDataFromTxt(INPUT_FILE, SEQLEN, STEP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRVf9KDHnSV9",
        "outputId": "4945abbb-ac41-4858-dbae-26813a4452ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n",
            "Downloading file from  https://raw.githubusercontent.com/cegacitua/colab-deep-learning/main/quijote.txt\n",
            "Number of lines: 32251\n",
            "Length of text: 2073831\n",
            "Downloading file from  https://raw.githubusercontent.com/cegacitua/colab-deep-learning/main/donjuantenorio.txt\n",
            "Number of lines: 5681\n",
            "Length of text: 2416002\n",
            "Downloading file from  https://raw.githubusercontent.com/cegacitua/colab-deep-learning/main/ladivinacomedia.txt\n",
            "Number of lines: 11373\n",
            "Length of text: 3105472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definir y Entrenar el Modelo RNN"
      ],
      "metadata": {
        "id": "tXUj5bwDZcZ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HClnsM0uc_x"
      },
      "outputs": [],
      "source": [
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "NUM_ITERATIONS = 25\n",
        "NUM_EPOCHS_PER_ITERATION = 1\n",
        "NUM_PREDS_PER_EPOCH = 100\n",
        "\n",
        "model_rnn = Sequential()\n",
        "model_rnn.add(\n",
        "    SimpleRNN(\n",
        "        HIDDEN_SIZE,\n",
        "        return_sequences=False,\n",
        "        input_shape=(SEQLEN, nb_chars),\n",
        "        unroll=True)\n",
        "    )\n",
        "model_rnn.add(Dense(nb_chars))\n",
        "model_rnn.add(Activation(\"softmax\"))\n",
        "\n",
        "model_rnn.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"rmsprop\"\n",
        "    )\n",
        "\n",
        "for iteration in range(NUM_ITERATIONS):\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Iteración #: %d\" % (iteration))\n",
        "\n",
        "    model_rnn.fit(X, y,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NUM_EPOCHS_PER_ITERATION)\n",
        "\n",
        "    test_idx = np.random.randint(len(input_chars))\n",
        "    test_chars = input_chars[test_idx]\n",
        "\n",
        "    print(\"Generando texto de la salida: %s\" % (test_chars))\n",
        "    print(test_chars, end=\"\")\n",
        "\n",
        "    for i in range(NUM_PREDS_PER_EPOCH):\n",
        "        Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
        "        for j, ch in enumerate(test_chars):\n",
        "            Xtest[0, j, char2index[ch]] = 1\n",
        "        pred = model_rnn.predict(Xtest, verbose=0)[0]\n",
        "        ypred = index2char[np.argmax(pred)]\n",
        "        print(ypred, end=\"\")\n",
        "\n",
        "        test_chars = test_chars[1:] + ypred\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definir y Entrenar el Modelo LSTM"
      ],
      "metadata": {
        "id": "M9GZOH_TZpn8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Id_3Q1K8uc_y"
      },
      "outputs": [],
      "source": [
        "model_lstm = Sequential()\n",
        "model_lstm.add(\n",
        "    LSTM(\n",
        "        HIDDEN_SIZE,\n",
        "        return_sequences=False,\n",
        "        input_shape=(SEQLEN, nb_chars),\n",
        "        unroll=True)\n",
        "    )\n",
        "model_lstm.add(Dense(nb_chars))\n",
        "model_lstm.add(Activation(\"softmax\"))\n",
        "\n",
        "model_lstm.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"rmsprop\"\n",
        "    )\n",
        "\n",
        "for iteration in range(NUM_ITERATIONS):\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Iteración #: %d\" % (iteration))\n",
        "\n",
        "    model_lstm.fit(X, y,\n",
        "                   batch_size=BATCH_SIZE,\n",
        "                   epochs=NUM_EPOCHS_PER_ITERATION)\n",
        "\n",
        "    test_idx = np.random.randint(len(input_chars))\n",
        "    test_chars = input_chars[test_idx]\n",
        "\n",
        "    print(\"Generando texto de la salida: %s\" % (test_chars))\n",
        "    print(test_chars, end=\"\")\n",
        "\n",
        "    for i in range(NUM_PREDS_PER_EPOCH):\n",
        "        Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
        "        for j, ch in enumerate(test_chars):\n",
        "            Xtest[0, j, char2index[ch]] = 1\n",
        "        pred = model_lstm.predict(Xtest, verbose=0)[0]\n",
        "        ypred = index2char[np.argmax(pred)]\n",
        "        print(ypred, end=\"\")\n",
        "\n",
        "        test_chars = test_chars[1:] + ypred\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKet_MVLuc_0"
      },
      "outputs": [],
      "source": [
        "# Modelo. SingleRNN con una capa fully connected para calcular la predicción\n",
        "\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "NUM_ITERATIONS = 25\n",
        "NUM_EPOCHS_PER_ITERATION = 1\n",
        "NUM_PREDS_PER_EPOCH = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(\n",
        "    SimpleRNN(\n",
        "        HIDDEN_SIZE,\n",
        "        return_sequences=False,\n",
        "                                        #-> Numero de caracteres distintos en el texto\n",
        "        input_shape=(SEQLEN, nb_chars), #-> Las cadenas de entrenamiento son de 10\n",
        "        unroll=True)\n",
        "    )\n",
        "model.add(Dense(nb_chars))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"rmsprop\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_WnQWq2uc_1"
      },
      "outputs": [],
      "source": [
        "# Entrenamos el modelo en n iteraciones y probamos la salida en cada iteración\n",
        "\n",
        "for iteration in range(NUM_ITERATIONS):\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Iteración #: %d\" % (iteration))\n",
        "\n",
        "    #Entrenamiento de la iteración\n",
        "    model.fit(X, y,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=NUM_EPOCHS_PER_ITERATION)\n",
        "\n",
        "    # test de la iteración\n",
        "    #en base a una semilla (texto inicial), generamos una salida\n",
        "    test_idx = np.random.randint(len(input_chars))\n",
        "    test_chars = input_chars[test_idx]\n",
        "\n",
        "    print(\"Generando texto de la salida: %s\" % (test_chars))\n",
        "    print(test_chars, end=\"\")\n",
        "\n",
        "    for i in range(NUM_PREDS_PER_EPOCH):\n",
        "        Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
        "        for i, ch in enumerate(test_chars):   #-> Codificamos los caracteres\n",
        "            Xtest[0, i, char2index[ch]] = 1\n",
        "        pred = model.predict(Xtest, verbose=0)[0]\n",
        "        ypred = index2char[np.argmax(pred)] #-> Decodificamos la predicción\n",
        "        print(ypred, end=\"\")\n",
        "\n",
        "        test_chars = test_chars[1:] + ypred\n",
        "    print()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}